{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-publicity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "numGPUs = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", numGPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D,Dropout,Activation,MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import talos\n",
    "import os\n",
    "import math\n",
    "import threading\n",
    "from matplotlib import pyplot\n",
    "import tensorflow_datasets as tfds\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ADAMApprox import AdamApprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "numClients = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "dataset_name = 'svhn_cropped'\n",
    "experiment_name = 'svhn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global parameters for grid search over activation function\n",
    "degree = 3\n",
    "interval = 3\n",
    "def reluApprox(x):\n",
    "    if degree == 3:  \n",
    "        if interval == 3:\n",
    "            return 0.7146 + 1.5000*K.pow(x/interval,1)+0.8793*K.pow(x/interval,2)\n",
    "        if interval == 5:\n",
    "            return 0.7865 + 2.5000*K.pow(x/interval,1)+1.88*K.pow(x/interval,2)\n",
    "        if interval == 7:\n",
    "            return 0.9003 + 3.5000*K.pow(x/interval,1)+2.9013*K.pow(x/interval,2)\n",
    "        if interval == 10:\n",
    "            return 1.1155 + 5*K.pow(x/interval,1)+4.4003*K.pow(x/interval,2)\n",
    "        if interval == 12:\n",
    "            return 1.2751 + 6*K.pow(x/interval,1)+5.3803*K.pow(x/interval,2)\n",
    "    if degree == 5:  \n",
    "        if interval == 7:\n",
    "            return 0.7521 + 3.5000*K.pow(x/interval,1)+4.3825*K.pow(x/interval,2)-1.7281*K.pow(x/interval,4)\n",
    "        if interval == 20:\n",
    "            return 1.3127 + 10*K.pow(x/interval,1)+15.7631*K.pow(x/interval,2)-7.6296*K.pow(x/interval,4)\n",
    "def sigmoidApprox(x):\n",
    "    if degree == 3:  \n",
    "        if interval == 3:\n",
    "            return 0.5 + 0.6997*K.pow(x/interval,1)-0.2649*K.pow(x/interval,3)\n",
    "        if interval == 5:\n",
    "            return 0.5 + 0.9917*K.pow(x/interval,1)-0.5592*K.pow(x/interval,3)\n",
    "        if interval == 7:\n",
    "            return 0.5 + 1.1511*K.pow(x/interval,1)-0.7517*K.pow(x/interval,3)\n",
    "        if interval == 8:\n",
    "            return 0.5 + 1.2010*K.pow(x/interval,1)-0.8156*K.pow(x/interval,2)\n",
    "        if interval == 12:\n",
    "            return 0.5 + 1.2384*K.pow(x/interval,1)-0.8647*K.pow(x/interval,2)\n",
    "def tanApprox(x):\n",
    "    if degree == 3: \n",
    "        if interval ==1:\n",
    "            return 0.9797*K.pow(x/interval,1)-0.2268*K.pow(x/interval,3)        \n",
    "        if interval ==2:\n",
    "            return 1.7329*K.pow(x/interval,1)-0.8454*K.pow(x/interval,3)\n",
    "        if interval == 3:\n",
    "            return 2.1673*K.pow(x/interval,1)-1.3358*K.pow(x/interval,3)\n",
    "        if interval == 5:\n",
    "            return 2.5338*K.pow(x/interval,1)-1.8051*K.pow(x/interval,3)\n",
    "        if interval == 7:\n",
    "            return 2.6629*K.pow(x/interval,1) -1.9801*K.pow(x/interval,3)\n",
    "        if interval == 12:\n",
    "            return 2.7599*K.pow(x/interval,1)-2.1140*K.pow(x/interval,2)\n",
    "    if degree == 12:\n",
    "        print('ooopssss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "def get_params_for_X_clients(x):    \n",
    "    global interval\n",
    "    \n",
    "    batch_size = [16]\n",
    "    epochs = [12]\n",
    "    learn_rate = [0.3]\n",
    "    momentum = [0.91]\n",
    "    act_fn = [reluApprox]\n",
    "    interval = 7\n",
    "    \n",
    "    param_grid = dict(learn_rate=learn_rate, momentum=momentum, batch_size=batch_size, epochs=epochs, act_fn=act_fn)\n",
    "    \n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, (5,5), activation=params['act_fn'], input_shape=input_shape))\n",
    "    model.add(AveragePooling2D((2,2)))\n",
    "    model.add(Conv2D(16, (5,5), activation=params['act_fn']))\n",
    "    model.add(AveragePooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120, activation=params['act_fn']))\n",
    "    model.add(Dense(84, activation=params['act_fn']))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-danger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tfds.as_numpy(tfds.load(dataset_name,\n",
    "                                                               split=['train','test'],\n",
    "                                                               batch_size=-1,\n",
    "                                                               as_supervised=True))\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "y_test_uncat = y_test\n",
    "\n",
    "#to use with mean sq error\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#shuffle both train and test once (to average between runs later on..)\n",
    "shuffler = np.random.permutation(len(x_train))\n",
    "x_train = x_train[shuffler]\n",
    "y_train = y_train[shuffler]\n",
    "shuffler = np.random.permutation(len(x_test))\n",
    "x_test = x_test[shuffler]\n",
    "y_test = y_test[shuffler]\n",
    "\n",
    "sample_height = x_train[0].shape[0]\n",
    "sample_width = x_train[0].shape[1]\n",
    "sample_channels = x_train[0].shape[2]\n",
    "\n",
    "\n",
    "input_shape = (sample_height, sample_width, sample_channels)\n",
    "\n",
    "def randomSplitClientsData(data,labels,numParties):\n",
    "    numSamplesPerClient = int(data.shape[0]/numParties)\n",
    "    print(numSamplesPerClient)\n",
    "    clientsData = np.zeros((numParties,int(numSamplesPerClient),sample_height,sample_width,sample_channels))\n",
    "    clientsDataLabels = np.zeros((numParties,int(numSamplesPerClient),num_classes))\n",
    "    #print(numSamplesPerClient)\n",
    "    ind = 0\n",
    "    for i in range(numParties):\n",
    "        clientsData[i] = data[ind:ind+numSamplesPerClient]\n",
    "        clientsDataLabels[i]=labels[ind:ind+numSamplesPerClient]\n",
    "        ind = ind+numSamplesPerClient\n",
    "    return clientsData, clientsDataLabels\n",
    "\n",
    "def prepare_data_for_X_clients(numClients):\n",
    "    clientsData, clientsDataLabels = randomSplitClientsData(x_train, y_train, numClients)\n",
    "    return clientsData, clientsDataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history, params):\n",
    "    print('##########################################################')\n",
    "    print(params)\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('MSE')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    #filename = sys.argv[0].split('/')[-1]\n",
    "    #pyplot.savefig(filename + '_plot.png')\n",
    "    #pyplot.close()\n",
    "    pyplot.show()\n",
    "    print('##########################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params_for_X_clients(numClients)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-knight",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_metrics_for_X_clients(numClients, clientsData, clientsDataLabels, test_params, keep_range):\n",
    "\n",
    "    metrics_res = np.zeros(numClients, dtype=object)\n",
    "    \n",
    "    \n",
    "    def client_test_metrics(i):\n",
    "        #Distribute load accross GPUs\n",
    "        with tf.device('/GPU:'+str(i%numGPUs)):\n",
    "            \n",
    "            print('training in client ', i)\n",
    "            model = get_model(test_params)\n",
    "            \n",
    "            optimizer = AdamApprox(keep_range=keep_range)\n",
    "            print('Precision :', precision)\n",
    "            optimizer.set_precision(precision)\n",
    "            model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, \n",
    "                          metrics=[\"accuracy\", tf.keras.metrics.Recall(),tf.keras.metrics.Precision()],\n",
    "                          run_eagerly=keep_range)\n",
    "            \n",
    "            hist.append(model.fit(x=clientsData[i],\n",
    "                        y=clientsDataLabels[i],\n",
    "                        epochs=test_params['epochs'],\n",
    "                        batch_size=test_params['batch_size'],\n",
    "                        verbose=1))\n",
    "            \n",
    "            hist_precision.append(optimizer.get_range())\n",
    "            \n",
    "            print('evaluation in client ', i)\n",
    "            metrics = model.evaluate(x_test, y_test)\n",
    "            metrics_res[i] = metrics\n",
    "            \n",
    "        \n",
    "    # Batch multithreading\n",
    "    n_batch = int(math.ceil(float(numClients)/(numGPUs)))\n",
    "    print(n_batch)\n",
    "    remaining_clients = numClients\n",
    "    for i in range(n_batch):\n",
    "        threads = list()\n",
    "\n",
    "        for j in range(min(numGPUs, remaining_clients)):\n",
    "            t = threading.Thread(target=client_test_metrics, args=(i*(numGPUs)+j,))\n",
    "            threads.append(t)\n",
    "            t.start()\n",
    "\n",
    "        for _,t in enumerate(threads):\n",
    "            remaining_clients -= 1\n",
    "            t.join()\n",
    "    \n",
    "    return metrics_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-manual",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = []\n",
    "hist_precision = []\n",
    "precisions = [0,0,0,0,0,0,0,0,0,0,\n",
    "              1,1,1,1,1,1,1,1,1,1,\n",
    "              2,2,2,2,2,2,2,2,2,2,\n",
    "              4,4,4,4,4,4,4,4,4,4,\n",
    "              6,6,6,6,6,6,6,6,6,6,\n",
    "              8,8,8,8,8,8,8,8,8,8,\n",
    "              10,10,10,10,10,10,10,10,10,10,\n",
    "              12,12,12,12,12,12,12,12,12,12,\n",
    "              'full','full','full','full','full''full','full','full','full','full']\n",
    "test_params = dict(learn_rate = params['learn_rate'][0],\n",
    "                   momentum = params['momentum'][0],\n",
    "                   batch_size = params['batch_size'][0],\n",
    "                   epochs = params['epochs'][0],\n",
    "                   act_fn = params['act_fn'][0])\n",
    "\n",
    "precision_res = [0] * len(precisions)\n",
    "clientsData, clientsDataLabels = prepare_data_for_X_clients(numClients)\n",
    "\n",
    "for i, p in enumerate(precisions):\n",
    "    global precision\n",
    "    precision = p\n",
    "    keep_range = p == 'full'\n",
    "    precision_res[i] = test_metrics_for_X_clients(numClients, clientsData, clientsDataLabels, test_params, keep_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [x for sublist in hist_precision for x in sublist]\n",
    "coeff_range = [min(flat_list), max(flat_list)]\n",
    "coeff_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(4,dtype=float)\n",
    "for i,p in enumerate(precision_res):\n",
    "    res[0] += p[0][0]\n",
    "    res[1] += p[0][1]\n",
    "    res[2] += p[0][2]\n",
    "    res[3] += p[0][3]\n",
    "    if i % 10 == 9:\n",
    "        print(res/10)\n",
    "        print()\n",
    "        res = np.zeros(4,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-rugby",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
